{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-04T12:15:57.092881Z",
     "iopub.status.busy": "2025-12-04T12:15:57.092697Z",
     "iopub.status.idle": "2025-12-04T12:16:02.844277Z",
     "shell.execute_reply": "2025-12-04T12:16:02.843386Z",
     "shell.execute_reply.started": "2025-12-04T12:15:57.092864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import DebertaV2Tokenizer\n",
    "\n",
    "class MSEDataset(Dataset):\n",
    "    \"\"\"用于回归评分任务的WSD数据集\"\"\"\n",
    "    \n",
    "    def __init__(self, json_path, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.samples = []\n",
    "        \n",
    "        # 1. 读取JSON\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # 2. 构造样本：每个原始条目（上下文/义项对）作为一个样本\n",
    "        for key, item in data.items():\n",
    "            \n",
    "            # --- 文本信息 ---\n",
    "            homonym = item[\"homonym\"]\n",
    "            definition = item[\"judged_meaning\"]\n",
    "            example = item[\"example_sentence\"]\n",
    "            # 完整上下文\n",
    "            context = f\"{item['precontext']} {item['sentence']} {item['ending']}\"\n",
    "            \n",
    "            # --- 标签信息 ---\n",
    "            # 直接使用平均值 (avg) 作为回归目标 T\n",
    "            target_avg = item[\"average\"] \n",
    "            # 使用标准差 (stdev) 作为损失函数中的容忍度 sigma\n",
    "            target_stdev = item[\"stdev\"]\n",
    "            \n",
    "            # 确保 avg 和 stdev 是有效的浮点数\n",
    "            if target_avg is None or target_stdev is None:\n",
    "                continue \n",
    "                \n",
    "            self.samples.append({\n",
    "                \"homonym\": homonym,\n",
    "                \"definition\": definition,\n",
    "                \"example\": example,\n",
    "                \"context\": context,\n",
    "                \"target_avg\": target_avg,   # 平均分 (T)\n",
    "                \"target_stdev\": target_stdev, # 标准差 (sigma)\n",
    "                \"sample_id\": item['sample_id'] # 原始ID\n",
    "            })\n",
    "            \n",
    "        print(f\"创建了 {len(self.samples)} 个回归训练样本\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # 构造输入文本\n",
    "        text_parts = (\n",
    "            f\"homonym：{sample['homonym']}\",\n",
    "            f\"Definition:{sample['definition']}\",\n",
    "            f\"Example:{sample['example']}\",\n",
    "            f\"Context:{sample['context']}\"\n",
    "        )\n",
    "        # 使用tokenizer的sep_token连接各个部分\n",
    "        text = self.tokenizer.sep_token.join(text_parts)\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # 移除batch维度\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        # 1. average 作为 labels (T)\n",
    "        encoding[\"labels\"] = torch.tensor(sample[\"target_avg\"], dtype=torch.float32)\n",
    "        \n",
    "        # 2. stdev 作为 stdevs (sigma)，用于自定义损失函数\n",
    "        \n",
    "        # 自定义时加重惩罚区间外的，均方误差（MSELoss时不需要）\n",
    "        # encoding[\"stdevs\"] = torch.tensor(sample[\"target_stdev\"], dtype=torch.float32)\n",
    "        \n",
    "        if \"token_type_ids\" in encoding:\n",
    "            del encoding[\"token_type_ids\"]\n",
    "            \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T12:16:04.819026Z",
     "iopub.status.busy": "2025-12-04T12:16:04.818214Z",
     "iopub.status.idle": "2025-12-04T12:16:29.449300Z",
     "shell.execute_reply": "2025-12-04T12:16:29.448548Z",
     "shell.execute_reply.started": "2025-12-04T12:16:04.818991Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 12:16:11.586979: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764850571.749361      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764850571.795001      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import DebertaV2Model, DebertaV2PreTrainedModel\n",
    "import torch\n",
    "\n",
    "# 输出维度为 1\n",
    "NUM_OUTPUTS = 1 \n",
    "\n",
    "class DebertaV2ForWSDScoring(DebertaV2PreTrainedModel):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.deberta = DebertaV2Model(config)\n",
    "        \n",
    "        # 回归头，输出维度为 1\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(config.hidden_dropout_prob), \n",
    "            nn.Linear(config.hidden_size, NUM_OUTPUTS) \n",
    "        )\n",
    "        self.post_init() \n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.deberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        \n",
    "        cls_output = outputs[0][:, 0, :]\n",
    "        predictions = self.regressor(cls_output) \n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # 使用标准的 nn.MSELoss\n",
    "            loss_fct = nn.MSELoss() \n",
    "            \n",
    "            # labels 是 float32 类型的 average (T)\n",
    "            # 确保 labels 的形状与 predictions 匹配 (batch_size, 1)\n",
    "            target = labels.float().view(-1, NUM_OUTPUTS)\n",
    "            loss = loss_fct(predictions.view(-1, NUM_OUTPUTS), target) # predictions.view(-1, 1)\n",
    "\n",
    "        # 返回结果 (loss, predictions) 或 predictions\n",
    "        return (loss, predictions) if loss is not None else predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T12:16:33.780263Z",
     "iopub.status.busy": "2025-12-04T12:16:33.779191Z",
     "iopub.status.idle": "2025-12-04T12:44:24.494151Z",
     "shell.execute_reply": "2025-12-04T12:44:24.493193Z",
     "shell.execute_reply.started": "2025-12-04T12:16:33.780233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForWSDScoring were not initialized from the model checkpoint at /kaggle/input/semeval/deberta-v3-large and are newly initialized: ['regressor.1.bias', 'regressor.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_47/2491924705.py:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建了 2280 个回归训练样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始微调 DeBERTaV2 回归模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='429' max='429' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [429/429 27:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>23.940400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.767100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>6.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.253400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.917800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练完成，模型和tokenizer已保存至 /kaggle/working/output_regression\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# from model import DebertaV2ForWSDScoring\n",
    "# from data_load import MSEDataset\n",
    "\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2Config, Trainer, TrainingArguments\n",
    "\n",
    "MODEL_NAME = \"/kaggle/input/semeval/deberta-v3-large\" \n",
    "TRAIN_JSON_PATH = \"/kaggle/input/semeval/data/train.json\"\n",
    "\n",
    "# 1. 加载 Tokenizer\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 2. 加载配置\n",
    "config = DebertaV2Config.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 对于回归任务，模型的输出类别数量 (NUM_OUTPUTS) 应该是 1。\n",
    "config.num_labels = 1 \n",
    "\n",
    "# 3. 初始化\n",
    "# DebertaV2ForWSDScoring 类已经修改为输出 1 个值并使用 nn.MSELoss\n",
    "model = DebertaV2ForWSDScoring.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    config=config\n",
    ")\n",
    "\n",
    "# 导入\n",
    "train_dataset = MSEDataset(\n",
    "    json_path=TRAIN_JSON_PATH, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = \"/kaggle/working/output_regression\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=10,                     \n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    # 禁用评估\n",
    "    eval_strategy=\"no\", \n",
    "    load_best_model_at_end=False, \n",
    "    warmup_steps=500,                       \n",
    "    weight_decay=0.01,                      \n",
    "    logging_dir='./logs_regression',       \n",
    "    logging_steps=50,                       \n",
    "    save_strategy=\"no\",                  # no\n",
    "    learning_rate=2e-5,                     \n",
    "    fp16=True,                              # 混合精度\n",
    "    seed=42,                                # 固定的随机种子\n",
    ")\n",
    "\n",
    "# 实例化 Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 启动训练\n",
    "print(\"开始微调 DeBERTaV2 回归模型...\")\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"训练完成，模型和tokenizer已保存至 {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval() \n",
    "print(\"Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "TEST_JSON_PATH = \"/kaggle/input/semeval/data/dev.json\" \n",
    "INFERENCE_BATCH_SIZE = 32 \n",
    "OUTPUT_JSONL_PATH = \"/kaggle/working/test_predictions.jsonl\"\n",
    "\n",
    "\n",
    "device = model.device \n",
    "model.eval() # 切换到评估模式\n",
    "\n",
    "print(f\"Model is on: {device}\")\n",
    "print(f\"Using Test/Inference file: {TEST_JSON_PATH}\")\n",
    "\n",
    "dev_dataset = MSEDataset(\n",
    "    json_path=TEST_JSON_PATH, \n",
    "    tokenizer=tokenizer, \n",
    ") \n",
    "dev_dataloader = DataLoader(\n",
    "    dev_dataset,\n",
    "    sampler=SequentialSampler(dev_dataset),\n",
    "    batch_size=INFERENCE_BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "all_results = []\n",
    "print(\"\\n***** 开始批量推理 *****\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dev_dataloader, desc=\"Inferencing\"):\n",
    "        \n",
    "        # 核心：所有字段都已读入 batch 字典。我们只提取需要的输入和 ID。\n",
    "        ids = batch[\"id\"] \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        \n",
    "        # batch[\"labels\"] (avg) 和 batch[\"stdevs\"] 被一起读入，但忽略。\n",
    "        \n",
    "        # 运行模型 (不传入 labels，模型只做前向传播)\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # 提取预测值 (logits/scores)\n",
    "        predictions = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "        predicted_scores = predictions.squeeze().cpu().tolist()\n",
    "        \n",
    "        # 收集结果\n",
    "        for json_key, score in zip(ids, predicted_scores): \n",
    "            # 最终评分四舍五入并限制在 [1.0, 5.0]\n",
    "            final_score = round(max(1.0, min(5.0, score)))\n",
    "            \n",
    "            all_results.append({\n",
    "                \"id\": json_key, \n",
    "                \"prediction\": final_score\n",
    "            })\n",
    "\n",
    "print(\"\\n推理完成。\")\n",
    "\n",
    "# 保存为 JSON Lines (.jsonl)\n",
    "\n",
    "print(f\"开始保存 {len(all_results)} 条结果到 {OUTPUT_JSONL_PATH}...\")\n",
    "\n",
    "with open(OUTPUT_JSONL_PATH, 'w', encoding='utf-8') as f:\n",
    "    for result in all_results:\n",
    "        f.write(json.dumps(result) + '\\n')\n",
    "\n",
    "print(f\"所有预测结果已保存到 {OUTPUT_JSONL_PATH}\")\n",
    "\n",
    "for result in all_results[:5]:\n",
    "    print(f\"{result}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8903723,
     "sourceId": 13989598,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
