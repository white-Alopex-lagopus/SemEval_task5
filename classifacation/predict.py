import torch
import os
import json
from torch.utils.data import DataLoader
from transformers import DebertaV2Tokenizer, AutoConfig

# âš ï¸ ç¡®ä¿å¯¼å…¥äº†æ‚¨çš„è‡ªå®šä¹‰ç±»
from model import DebertaV2ForWSDScoring 
from data_load import SimpleWSDDataset 
# æ³¨æ„ï¼šSimpleWSDDataset é»˜è®¤ä¼šè·³è¿‡ 'nonsensical' ä¸º True çš„æ ·æœ¬ã€‚
# å¦‚æœ dev.json ä¸­åŒ…å« nonsensical æ ·æœ¬ä¸”éœ€è¦è¯„åˆ†ï¼Œä½ éœ€è¦ä¸€ä¸ªä¸åŒçš„ Dataset ç±»ã€‚
# å‡è®¾ dev.json åªåŒ…å«éœ€è¦è¯„åˆ†çš„æ ·æœ¬ï¼Œä¸”æˆ‘ä»¬åªå…³å¿ƒè¯„åˆ†ç»“æœã€‚


# --- é…ç½® ---
OUTPUT_DIR = "./infer"
DEV_JSON_PATH = "../data/dev.json"  # å‡è®¾ dev.json è·¯å¾„
RESULT_JSONL_PATH = "./dev_predictions.jsonl"
BATCH_SIZE = 32  # å¯ä»¥æ ¹æ®æ‚¨çš„ GPU å†…å­˜è°ƒæ•´
NUM_LABELS = 5   # 1-5åˆ†
MAX_LENGTH = 512

# --- 1. è®¾ç½®è®¾å¤‡ ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ æ¨¡å‹æ¨ç†å°†åœ¨è®¾å¤‡ä¸Šè¿è¡Œ: {device}")

# --- 2. åŠ è½½æ¨¡å‹å’Œ Tokenizer ---
try:
    print(f"æ­£åœ¨ä» {OUTPUT_DIR} åŠ è½½æ¨¡å‹å’Œ Tokenizer...")
    config = AutoConfig.from_pretrained(OUTPUT_DIR)
    tokenizer = DebertaV2Tokenizer.from_pretrained(OUTPUT_DIR)
    
    model = DebertaV2ForWSDScoring.from_pretrained(OUTPUT_DIR, config=config)
    
    model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹å’Œ Tokenizer åŠ è½½æˆåŠŸã€‚")

except Exception as e:
    print(f"âŒ åŠ è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥ {OUTPUT_DIR} ä¸­çš„æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼Œä»¥åŠ 'model.py' å’Œ 'data_load.py' æ˜¯å¦æ­£ç¡®ã€‚")
    print(f"é”™è¯¯ä¿¡æ¯: {e}")
    exit()

# --- 3. åŠ è½½æ•°æ®é›†å’Œ DataLoader ---
# âš ï¸ æ³¨æ„: SimpleWSDDataset é»˜è®¤ä¼šè¯»å– JSON ä¸­çš„ score ä½œä¸º labelsã€‚
# å¯¹äºæ¨ç†ï¼Œæˆ‘ä»¬åªæ˜¯ç”¨å®ƒæ¥ç”Ÿæˆ input_idsï¼Œlabels ä¼šè¢«å¿½ç•¥ã€‚
print(f"æ­£åœ¨åŠ è½½ {DEV_JSON_PATH} æ•°æ®é›†...")
test_dataset = SimpleWSDDataset(
    json_path=DEV_JSON_PATH, 
    tokenizer=tokenizer, 
    max_length=MAX_LENGTH
)

test_dataloader = DataLoader(
    test_dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=False, 
    # Tokenizer å·²ç»è¿›è¡Œäº† paddingï¼Œè¿™é‡Œä¸éœ€è¦ collate_fn
    collate_fn=None 
)
print(f"å…±ç”Ÿæˆ {len(test_dataset)} ä¸ªæ¨ç†æ ·æœ¬ï¼Œåˆ† {len(test_dataloader)} æ‰¹æ¬¡å¤„ç†ã€‚")

# --- 4. æ‰§è¡Œæ‰¹é‡æ¨ç† ---
all_predictions = []
all_sample_ids = []

print("--- å¼€å§‹æ‰¹é‡æ¨ç† ---")
with torch.no_grad():
    for step, batch in enumerate(test_dataloader):
        # 4.1 å‡†å¤‡è¾“å…¥
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        
        # 4.2 è¿è¡Œæ¨¡å‹
        # model.forward åªè¿”å› logitsï¼Œå› ä¸º batch ä¸­æ²¡æœ‰ labels
        logits = model(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        # logits.shape: [batch_size, 5] (5ä¸ªç±»åˆ«)

        # 4.3 åå¤„ç†ï¼šæ‰¾å‡ºé¢„æµ‹çš„ 1-5 åˆ†
        # æ‰¾åˆ° 5 ä¸ªç±»åˆ«ä¸­æ¦‚ç‡æœ€é«˜çš„ç´¢å¼• (0-4)
        predicted_scores_index = torch.argmax(logits, dim=1)
        # è½¬æ¢ä¸º 1-5 åˆ†
        predicted_scores = predicted_scores_index + 1
        
        all_predictions.extend(predicted_scores.cpu().numpy())
        
        # 4.4 æ”¶é›†æ ·æœ¬ ID
        # âš ï¸ WARNING: DataLoader è¿”å›çš„ batch ä¸­ä¸åŒ…å« SimpleWSDDataset ä¸­çš„ 'sample_id'ã€‚
        # ç”±äº SimpleWSDDataset æ˜¯åŸºäºç´¢å¼•çš„ï¼Œæˆ‘ä»¬å¿…é¡»æ‰‹åŠ¨æ˜ å°„ IDã€‚
        start_idx = step * BATCH_SIZE
        end_idx = min((step + 1) * BATCH_SIZE, len(test_dataset))
        
        # ä» dataset å¯¹è±¡çš„ samples åˆ—è¡¨ä¸­æå– sample_id
        current_sample_ids = [
            test_dataset.samples[i]['sample_id'] 
            for i in range(start_idx, end_idx)
        ]
        all_sample_ids.extend(current_sample_ids)
        
        if (step + 1) % 50 == 0:
            print(f"å·²å¤„ç† {step + 1}/{len(test_dataloader)} æ‰¹æ¬¡...")

print("âœ… æ¨ç†å®Œæˆã€‚")

# --- 5. ä¿å­˜ç»“æœåˆ° JSONL æ–‡ä»¶ ---

print(f"æ­£åœ¨ä¿å­˜ç»“æœåˆ° {RESULT_JSONL_PATH}...")
output_records = []

# 5.1 æ„é€  JSONL è®°å½•
for sample_id, prediction in zip(all_sample_ids, all_predictions):
    # SimpleWSDDataset çš„ sample_id æ˜¯ "original_id_choice_idx"
    # æˆ‘ä»¬æŒ‰ç…§é¢˜ç›®çš„è¦æ±‚ï¼Œä¿å­˜è¿™ä¸ªå±•å¹³åçš„æ ·æœ¬ ID å’Œé¢„æµ‹å¾—åˆ†
    output_records.append({
        "id": str(sample_id),
        "prediction": int(prediction) # é¢„æµ‹çš„ 1-5 åˆ†
    })

# 5.2 å†™å…¥ JSONL æ–‡ä»¶
with open(RESULT_JSONL_PATH, 'w', encoding='utf-8') as f:
    for record in output_records:
        f.write(json.dumps(record, ensure_ascii=False) + '\n')

print(f"ğŸ‰ ç»“æœæˆåŠŸä¿å­˜åˆ° {RESULT_JSONL_PATH}ã€‚å…± {len(output_records)} æ¡è®°å½•ã€‚")

# ç¤ºä¾‹è¾“å‡ºæ ¼å¼æ£€æŸ¥ï¼š
# {"id": "sample_123_0", "prediction": 5}