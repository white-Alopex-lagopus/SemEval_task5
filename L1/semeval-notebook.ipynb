{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13989598,"sourceType":"datasetVersion","datasetId":8903723}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nimport json\nimport torch\nfrom torch.utils.data import Dataset\nfrom transformers import DebertaV2Tokenizer\n\nclass MSEDataset(Dataset):\n    \"\"\"用于回归评分任务的WSD数据集\"\"\"\n    \n    def __init__(self, json_path, tokenizer, max_length=512):\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.samples = []\n        \n        # 1. 读取JSON\n        with open(json_path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        \n        # 2. 构造样本：每个原始条目（上下文/义项对）作为一个样本\n        for key, item in data.items():\n            \n            # --- 文本信息 ---\n            homonym = item[\"homonym\"]\n            definition = item[\"judged_meaning\"]\n            example = item[\"example_sentence\"]\n            # 完整上下文\n            context = f\"{item['precontext']} {item['sentence']} {item['ending']}\"\n            \n            # --- 标签信息 ---\n            # 直接使用平均值 (avg) 作为回归目标 T\n            target_avg = item[\"average\"] \n            # 使用标准差 (stdev) 作为损失函数中的容忍度 sigma\n            target_stdev = item[\"stdev\"]\n            \n            # 确保 avg 和 stdev 是有效的浮点数\n            if target_avg is None or target_stdev is None:\n                # 实际应用中可能需要更复杂的缺失值处理\n                continue \n                \n            self.samples.append({\n                \"json_key\": key,\n                \"homonym\": homonym,\n                \"definition\": definition,\n                \"example\": example,\n                \"context\": context,\n                \"target_avg\": target_avg,   # 平均分 (T)\n                \"target_stdev\": target_stdev, # 标准差 (sigma)\n                \"sample_id\": item['sample_id'] # 原始ID\n            })\n            \n        print(f\"创建了 {len(self.samples)} 个回归训练样本\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n        \n        # 构造输入文本\n        text_parts = (\n            f\"homonym：{sample['homonym']}\",\n            f\"Definition:{sample['definition']}\",\n            f\"Example:{sample['example']}\",\n            f\"Context:{sample['context']}\"\n        )\n        # 使用tokenizer的sep_token连接各个部分\n        text = self.tokenizer.sep_token.join(text_parts)\n        \n        # Tokenize\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n        \n        # 移除batch维度\n        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n        \n        # 重点修改：添加两个回归标签\n        \n        # 1. average 作为 labels (T)\n        encoding[\"labels\"] = torch.tensor(sample[\"target_avg\"], dtype=torch.float32)\n        \n        # 2. stdev 作为 stdevs (sigma)，用于自定义损失函数\n        # 自定义时加重惩罚区间外的，均方误差（MSELoss时不需要）\n        # encoding[\"stdevs\"] = torch.tensor(sample[\"target_stdev\"], dtype=torch.float32)\n\n        encoding[\"id\"] = sample[\"json_key\"]\n        \n        if \"token_type_ids\" in encoding:\n            del encoding[\"token_type_ids\"]\n            \n        return encoding","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:23:53.383424Z","iopub.execute_input":"2025-12-05T06:23:53.383690Z","iopub.status.idle":"2025-12-05T06:23:59.987255Z","shell.execute_reply.started":"2025-12-05T06:23:53.383668Z","shell.execute_reply":"2025-12-05T06:23:59.986326Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import DebertaV2Model, DebertaV2PreTrainedModel\nimport torch\n\n# 输出维度为 1\nNUM_OUTPUTS = 1 \n\nclass DebertaV2ForWSDScoring(DebertaV2PreTrainedModel):\n    \n    def __init__(self, config):\n        super().__init__(config)\n        self.deberta = DebertaV2Model(config)\n        \n        # 回归头，输出维度为 1\n        self.regressor = nn.Sequential(\n            nn.Dropout(config.hidden_dropout_prob), \n            nn.Linear(config.hidden_size, NUM_OUTPUTS) \n        )\n        self.post_init() \n\n    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n        # ... (DeBERTaV2 主体运行部分不变) ...\n        outputs = self.deberta(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n        )\n        \n        cls_output = outputs[0][:, 0, :]\n        predictions = self.regressor(cls_output) \n\n        loss = None\n        if labels is not None:\n            # 使用标准的 nn.MSELoss\n            loss_fct = nn.L1Loss() \n            \n            # labels 是 float32 类型的 average (T)\n            # 确保 labels 的形状与 predictions 匹配 (batch_size, 1)\n            target = labels.float().view(-1, NUM_OUTPUTS)\n            loss = loss_fct(predictions.view(-1, NUM_OUTPUTS), target) # predictions.view(-1, 1)\n\n        # 返回结果 (loss, predictions) 或 predictions\n        return (loss, predictions) if loss is not None else predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:24:10.980473Z","iopub.execute_input":"2025-12-05T06:24:10.981783Z","iopub.status.idle":"2025-12-05T06:24:38.107565Z","shell.execute_reply.started":"2025-12-05T06:24:10.981753Z","shell.execute_reply":"2025-12-05T06:24:38.106780Z"}},"outputs":[{"name":"stderr","text":"2025-12-05 06:24:18.255744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764915858.480789      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764915858.553548      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n# from model import DebertaV2ForWSDScoring\n# from data_load import MSEDataset\n\nfrom transformers import DebertaV2Tokenizer, DebertaV2Config, Trainer, TrainingArguments\n# 假设您的模型和数据集类定义在 model.py 和 data_load.py 中\n# from model import DebertaV2ForWSDScoring  # 您的回归模型\n# from data_load import MSEDataset          # 您的回归数据集（原SimpleWSDDataset修改版）\n\n# 建议使用相对较小的版本开始，以节省资源\nMODEL_NAME = \"/kaggle/input/semeval/deberta-v3-large\" \nTRAIN_JSON_PATH = \"/kaggle/input/semeval/data/train.json\" # 假设您的数据路径\n\n# 1. 加载 Tokenizer\ntokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n\n# 2. 加载配置（用于初始化您的模型类）\nconfig = DebertaV2Config.from_pretrained(MODEL_NAME)\n\n# **【关键修改】**：\n# 对于回归任务，模型的输出类别数量 (NUM_OUTPUTS) 应该是 1。\n# 您的自定义模型 DebertaV2ForWSDScoring 的 __init__ 方法应该使用这个配置。\nconfig.num_labels = 1 \n\n# 3. 初始化您的自定义模型\n# 请确保您的 DebertaV2ForWSDScoring 类已经修改为输出 1 个值并使用 nn.MSELoss\n# 假设您已在脚本中导入了 DebertaV2ForWSDScoring 类\nmodel = DebertaV2ForWSDScoring.from_pretrained(\n    MODEL_NAME, \n    config=config\n)\n\n# 导入您的数据集类 (我们称之为 MSEDataset 或使用您修改后的 SimpleWSDDataset)\ntrain_dataset = MSEDataset( # 假设这是您修改后输出 float labels (avg) 的类\n    json_path=TRAIN_JSON_PATH, \n    tokenizer=tokenizer\n)\n\nOUTPUT_DIR = \"/kaggle/working/output_regression\"\n\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    num_train_epochs=3,                     \n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    # ------------------------------------------------\n    # 禁用评估\n    eval_strategy=\"no\", \n    load_best_model_at_end=False, \n    # ------------------------------------------------\n    warmup_steps=500,                       \n    weight_decay=0.01,                      \n    logging_dir='./logs_regression',       \n    logging_steps=50,                       \n    save_strategy=\"no\",                  # no\n    learning_rate=2e-5,                     \n    fp16=True,                              # 混合精度训练，加速\n    # **【可选优化】**：报告指标为回归任务\n    # metric_for_best_model=\"eval_loss\",      # 尽管我们禁用了评估，但保留此设置\n    # greater_is_better=False,\n    seed=42,                                # 固定的随机种子\n)\n\n# 实例化 Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n    # **【回归任务不需要 special data collator】**：\n    # Data collator 默认会处理回归任务的 float labels\n)\n\n# 启动训练\nprint(\"开始微调 DeBERTaV2 回归模型...\")\ntrainer.train()\n\n# 训练结束后，保存最终模型\ntrainer.save_model(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)\nprint(f\"训练完成，模型和tokenizer已保存至 {OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:24:51.194785Z","iopub.execute_input":"2025-12-05T06:24:51.195395Z","iopub.status.idle":"2025-12-05T06:51:46.884283Z","shell.execute_reply.started":"2025-12-05T06:24:51.195370Z","shell.execute_reply":"2025-12-05T06:51:46.883647Z"}},"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForWSDScoring were not initialized from the model checkpoint at /kaggle/input/semeval/deberta-v3-large and are newly initialized: ['regressor.1.bias', 'regressor.1.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_47/2491924705.py:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"name":"stdout","text":"创建了 2280 个回归训练样本\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"name":"stdout","text":"开始微调 DeBERTaV2 回归模型...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='429' max='429' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [429/429 26:25, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>10.884700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>4.482600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>4.381700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>4.270200</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>4.141800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>4.403300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>4.133500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.996600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"训练完成，模型和tokenizer已保存至 /kaggle/working/output_regression\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"model.eval() \nprint(\"Model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:55:45.164472Z","iopub.execute_input":"2025-12-05T06:55:45.165813Z","iopub.status.idle":"2025-12-05T06:55:45.171391Z","shell.execute_reply.started":"2025-12-05T06:55:45.165781Z","shell.execute_reply":"2025-12-05T06:55:45.170614Z"}},"outputs":[{"name":"stdout","text":"Model\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import json\nimport torch\nfrom torch.utils.data import DataLoader, SequentialSampler\nfrom tqdm import tqdm\n# 假设您已导入 MSEDataset 类\n\n# ----------------------------------------------------------------------\n# 路径和配置\n# ----------------------------------------------------------------------\n# 假设测试集路径为 /kaggle/input/semeval/data/test.json (或您提供的 dev.json)\nTEST_JSON_PATH = \"/kaggle/input/semeval/data/dev.json\" \nINFERENCE_BATCH_SIZE = 32 \nOUTPUT_JSONL_PATH = \"/kaggle/working/test_predictions.jsonl\"\n\n# 确定设备 (假设 model 已经移动到正确的设备)\ndevice = model.device \nmodel.eval() # 切换到评估模式\n\nprint(f\"Model is on: {device}\")\nprint(f\"Using Test/Inference file: {TEST_JSON_PATH}\")\n\n# ----------------------------------------------------------------------\n# 1. 实例化推理数据集和 DataLoader\n# ----------------------------------------------------------------------\n# 使用 MSEDataset，它会读取所有的字段 (包括 avg 作为 labels)\ndev_dataset = MSEDataset(\n    json_path=TEST_JSON_PATH, \n    tokenizer=tokenizer, \n) \ndev_dataloader = DataLoader(\n    dev_dataset,\n    sampler=SequentialSampler(dev_dataset),\n    batch_size=INFERENCE_BATCH_SIZE\n)\n\n# ----------------------------------------------------------------------\n# 2. 运行推理循环 (在代码层面忽略标签)\n# ----------------------------------------------------------------------\nall_results = []\nprint(\"\\n***** 开始批量推理 *****\")\n\nwith torch.no_grad():\n    for batch in tqdm(dev_dataloader, desc=\"Inferencing\"):\n        \n        # 核心：所有字段都已读入 batch 字典。我们只提取需要的输入和 ID。\n        ids = batch[\"id\"] \n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        \n        # ⚠️ 注意：batch[\"labels\"] (avg) 和 batch[\"stdevs\"] 被一起读入，但我们在这里忽略了它们。\n        \n        # 运行模型 (不传入 labels，模型只做前向传播)\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        # 提取预测值 (logits/scores)\n        predictions = outputs[0] if isinstance(outputs, tuple) else outputs\n        predicted_scores = predictions.squeeze().cpu().tolist()\n        \n        # 收集结果\n        for json_key, score in zip(ids, predicted_scores): \n            # 最终评分四舍五入并限制在 [1.0, 5.0]\n            final_score = round(max(1.0, min(5.0, score)))\n            \n            all_results.append({\n                \"id\": json_key, \n                \"prediction\": final_score\n            })\n\nprint(\"\\n推理完成。\")\n\n# ----------------------------------------------------------------------\n# 3. 保存为 JSON Lines (.jsonl)\n# ----------------------------------------------------------------------\n\nprint(f\"开始保存 {len(all_results)} 条结果到 {OUTPUT_JSONL_PATH}...\")\n\nwith open(OUTPUT_JSONL_PATH, 'w', encoding='utf-8') as f:\n    for result in all_results:\n        f.write(json.dumps(result) + '\\n')\n\nprint(f\"所有预测结果已保存到 {OUTPUT_JSONL_PATH}\")\n\n# 打印全部结果\nprint(\"\\n--- 全部预测结果 (JSON Lines 格式) ---\")\nfor result in all_results[:5]:\n    print(f\"{result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:55:47.885514Z","iopub.execute_input":"2025-12-05T06:55:47.886498Z","iopub.status.idle":"2025-12-05T06:57:09.977915Z","shell.execute_reply.started":"2025-12-05T06:55:47.886468Z","shell.execute_reply":"2025-12-05T06:57:09.976077Z"}},"outputs":[{"name":"stdout","text":"Model is on: cuda:0\nUsing Test/Inference file: /kaggle/input/semeval/data/dev.json\n创建了 588 个回归训练样本\n\n***** 开始批量推理 *****\n","output_type":"stream"},{"name":"stderr","text":"Inferencing: 100%|██████████| 19/19 [01:22<00:00,  4.32s/it]","output_type":"stream"},{"name":"stdout","text":"\n推理完成。\n开始保存 588 条结果到 /kaggle/working/test_predictions.jsonl...\n所有预测结果已保存到 /kaggle/working/test_predictions.jsonl\n\n--- 全部预测结果 (JSON Lines 格式) ---\n{'id': '0', 'prediction': 3}\n{'id': '1', 'prediction': 3}\n{'id': '2', 'prediction': 3}\n{'id': '3', 'prediction': 3}\n{'id': '4', 'prediction': 3}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5}]}